{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before go through modules, first import all packets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "import matplotlib.image as mpimg # mpimg 用于读取图片\n",
    "import numpy as np\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Load Images from file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define several methods.\n",
    "1. create batch pair (img and label)\n",
    "2. load image\n",
    "3. print image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "import matplotlib.image as mpimg # mpimg 用于读取图片\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "item = 0\n",
    "def next_batch(x,y,batch_size):\n",
    "    global item\n",
    "    while True:\n",
    "        item += batch_size\n",
    "        if item+2*batch_size > x.shape[0]:   item = 0\n",
    "        return x[item:item+batch_size,:],y[item:item+batch_size,:]\n",
    "\n",
    "\n",
    "def load_img(path= \"D:\\\\Unistar\\\\TV Logo Recognition\\\\Logo Data\\\\cctv5+\",num = 10,label = 0,total_label = 3):\n",
    "    a_s = []\n",
    "    for i in range(num):\n",
    "        file = path+ \"/video_out_sd_{}.yuv\".format(i)\n",
    "\n",
    "        f = open(file,'rb')\n",
    "        buf = f.read()\n",
    "        buf = np.frombuffer(buf, dtype=np.uint8)\n",
    "        buf = buf.reshape([1,96*35])\n",
    "        if i == 0:    matrix = buf\n",
    "        else:         matrix = np.concatenate([matrix,buf],axis = 0)\n",
    "        a_s.append(buf)\n",
    "        #lena =  Image.frombuffer('L',(96,35),buf)\n",
    "        #lena.show()\n",
    "        #time.sleep(1)\n",
    "        f.close()\n",
    "\n",
    "    #matrix = np.array(a_s)\n",
    "    \n",
    "    #print(matrix.shape)\n",
    "    label_s = np.zeros( (matrix.shape[0],total_label),dtype = np.float32 )\n",
    "    label_s[:,label] = 1\n",
    "    return matrix,label_s\n",
    "\n",
    "def showImgfrombytes(bytestream,shape = (96,35)):\n",
    "    lena =  Image.frombuffer('L',shape,bytestream)\n",
    "    lena = lena.transpose(Image.FLIP_TOP_BOTTOM) #上下互换\n",
    "    lena.show()\n",
    "    #draw = ImageDraw.Draw(img)\n",
    "    \n",
    "\n",
    "def listmapping(channel_list,LOGO_s):\n",
    "    out_s = []\n",
    "    for i in channel_list:\n",
    "        out_s.append(LOGO_s[int(i)][0])\n",
    "    return out_s\n",
    "    \n",
    "    \n",
    "TV_LOGO_s = [('cctv5+',1022),('cctv1hd',1044),('jswshd',1021),('dfwshd',1001),('cctv5',1001),\n",
    "             ('zjwshd',1001),('cctv1',1001),('bjwshd',1001),('hnwshd',1001),('cctv5hd',1001)]\n",
    "CLASSES = len(TV_LOGO_s)\n",
    "LOGOPATH = \"D:\\\\Unistar\\\\TV Logo Recognition\\\\Logo Data 96x35\\\\\"\n",
    "img_s   = [0]*CLASSES\n",
    "label_s = [0]*CLASSES\n",
    "for i in range(CLASSES):\n",
    "    img_s[i],label_s[i] = load_img(LOGOPATH+TV_LOGO_s[i][0],int(TV_LOGO_s[i][1]),i,CLASSES)\n",
    "\n",
    "\n",
    "img   = img_s[0]\n",
    "label = label_s[0]\n",
    "for i in range(1,len(img_s)):\n",
    "    img   = np.concatenate([img,img_s[i]],axis = 0)\n",
    "    label = np.concatenate([label,label_s[i]],axis = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. shuffle all images and divided into tain set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8075, 3360) (8075, 10)\n",
      "(2019, 3360) (2019, 10)\n"
     ]
    }
   ],
   "source": [
    "permutation = np.random.permutation(img.shape[0])\n",
    "shuffled_img = img[permutation, :]\n",
    "shuffled_labels = label[permutation, :]\n",
    "\n",
    "total_num = img.shape[0]\n",
    "train_num = int(0.8*total_num)\n",
    "\n",
    "img_train   = shuffled_img[0:train_num,:]\n",
    "label_train = shuffled_labels[0:train_num,:]\n",
    "img_test    = shuffled_img[train_num:,:]\n",
    "label_test  = shuffled_labels[train_num:,:]\n",
    "\n",
    "print(img_train.shape, label_train.shape)\n",
    "print(img_test.shape, label_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. check the type for image sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8 float32\n"
     ]
    }
   ],
   "source": [
    "print(img_train.dtype,label_train.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Set up learning model, train the network and save checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. All input images are divided by 255 in order to be simple normalization\n",
    "2. batch normalization is applied: tf.layers.batch_normalization is preferred while tf.nn.batch_normalization is hard to use\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8075, 3360)\n",
      "0.172858\n",
      "0.995047\n",
      "0.998019\n",
      "0.999009\n",
      "0.999009\n",
      "0.999505\n",
      "0.999505\n",
      "0.999505\n",
      "0.999505\n",
      "0.999505\n",
      "0.999505\n",
      "0.999505\n",
      "0.999505\n",
      "0.999505\n",
      "0.999505\n",
      "0.999505\n",
      "0.999505\n",
      "0.999505\n",
      "0.999505\n",
      "0.999505\n",
      "0.999505\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "#mnist = input_data.read_data_sets(r\"D:\\MachineLearning\\minst\", one_hot=True)\n",
    "\n",
    "def batch_normal(Y,offset_Beta,scale_J,iteration):\n",
    "    exp_moving_avg = tf.train.ExponentialMovingAverage(0.998, iteration) # adding the iteration prevents from averaging across non-existing iterations\n",
    "    mean, variance = tf.nn.moments(Y, [0])\n",
    "    update_moving_averages = exp_moving_avg.apply([mean, variance])\n",
    "    m = exp_moving_avg.average(mean)\n",
    "    v = exp_moving_avg.average(variance)\n",
    "   # Ybn = tf.nn.batch_normalization(Y, m, v, offset_Beta, scale_J, 1e-5)\n",
    "    Ybn = tf.nn.batch_normalization(Y, mean, variance, offset_Beta, scale_J, 1e-5)\n",
    "    return Ybn,update_moving_averages\n",
    "\n",
    "\n",
    "def hidden_layer(X, sizeOutput, iteration = 10, non_linear_name = '',enable_bn=False):\n",
    "    sizeInput = X.shape[1]\n",
    "    W = tf.Variable( tf.truncated_normal([int(sizeInput),int(sizeOutput)],stddev=0.001) )\n",
    "    \n",
    "    if enable_bn:   \n",
    "        Z = tf.matmul(X,W)         #In bach norm, the bias B can be ommited due to the offset\n",
    "        scale_J = tf.Variable(tf.ones([int(sizeOutput)]))\n",
    "        offset_Beta = tf.Variable(tf.zeros([int(sizeOutput)]))\n",
    "        Y, update_moving_averages = batch_normal(Z,offset_Beta,scale_J, iteration)\n",
    "    else:           \n",
    "        B = tf.Variable(tf.zeros([1,sizeOutput]))\n",
    "        Y = tf.matmul(X,W) + B\n",
    "        \n",
    "        \n",
    "    if non_linear_name == '':             return   Y,0\n",
    "    elif non_linear_name == 'softmax':    A = tf.nn.softmax(Y)\n",
    "    elif non_linear_name == 'relu':       A = tf.nn.relu(Y)\n",
    "    elif non_linear_name == 'sigmoid':    A = tf.nn.sigmoid(Y)\n",
    "    return A, update_moving_averages\n",
    "\n",
    "\n",
    "def batch_normal_V2(X,iftraining):\n",
    "    return  tf.layers.batch_normalization(X, training=iftraining)\n",
    "    \n",
    "\n",
    "def hidden_layer_V2(X, sizeOutput, iteration = 10, non_linear_name = '',enable_bn=False, iftraining = True):\n",
    "    sizeInput = X.shape[1]\n",
    "    W = tf.Variable( tf.truncated_normal([int(sizeInput),int(sizeOutput)],stddev=0.1) )\n",
    "    \n",
    "    if enable_bn:   \n",
    "        Z = tf.matmul(X,W)         #In bach norm, the bias B can be ommited due to the offset\n",
    "        Y = batch_normal_V2(Z,iftraining)\n",
    "    else:           \n",
    "        B = tf.Variable(tf.zeros([1,sizeOutput]))\n",
    "        Y = tf.matmul(X,W) + B  \n",
    "        \n",
    "    if non_linear_name == '':             return   Y,0\n",
    "    elif non_linear_name == 'softmax':    A = tf.nn.softmax(Y)\n",
    "    elif non_linear_name == 'relu':       A = tf.nn.relu(Y)\n",
    "    elif non_linear_name == 'sigmoid':    A = tf.nn.sigmoid(Y)\n",
    "    return A, 0\n",
    "\n",
    "\n",
    "X       = tf.placeholder(tf.float32, [None, 96*35],name = 'Input')\n",
    "Y_LABEL = tf.placeholder(tf.float32, [None, CLASSES], name = 'Label')\n",
    "lr      = tf.placeholder(tf.float32, name = 'LearningRate')\n",
    "iters   = tf.placeholder(tf.int32, name = 'Iterations')\n",
    "iftraining = tf.placeholder(tf.bool,name = 'Mode')\n",
    "\n",
    "\n",
    "A0, update_ema0 = hidden_layer_V2(X,512, iters, 'relu',True,iftraining)\n",
    "A1, update_ema1 = hidden_layer_V2(A0,256, iters, 'relu',True,iftraining)\n",
    "A2, update_ema2 = hidden_layer_V2(A1,128,iters, 'relu',True,iftraining)\n",
    "A3, update_ema3 = hidden_layer_V2(A2,64, iters, 'relu',True,iftraining)\n",
    "A4, update_ema4 = hidden_layer_V2(A3,32, iters, 'relu',True,iftraining)\n",
    "Y_linear,nocare = hidden_layer_V2(A4, Y_LABEL.shape[1]) \n",
    "Y_predict       = tf.nn.softmax(Y_linear,name = 'Y_predict')\n",
    "#update_ema = tf.group(update_ema0, update_ema1, update_ema2, update_ema3, update_ema4)\n",
    "#update_ema = tf.group(update_ema0, update_ema2, update_ema3)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=Y_LABEL, logits=Y_linear))\n",
    "\n",
    "\n",
    "#optimizer = tf.train.AdamOptimizer(lr).minimize(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    #grads = optimizer.compute_gradients(cross_entropy)\n",
    "    #train_step = optimizer.apply_gradients(grads, global_step=global_step)\n",
    "    train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "\n",
    "max_learning_rate = 0.1\n",
    "min_learning_rate = 0.001\n",
    "decay_speed = 2000.0\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "img_train_float = np.float32(img_train/255)\n",
    "img_test_float = np.float32(img_test/255)\n",
    "print(img_train_float.shape)\n",
    "for _ in range(2001):\n",
    "    batch_xs, batch_ys= next_batch(img_train_float,label_train,500)\n",
    "    learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * np.exp(-_/decay_speed)\n",
    "    sess.run(train_step, feed_dict={X: batch_xs, Y_LABEL: batch_ys, lr:learning_rate, iftraining: True})\n",
    "    if _%100 == 0:\n",
    "        correct_prediction = tf.equal(tf.argmax(Y_linear, 1), tf.argmax(Y_LABEL, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        #print('This is round {} ...'.format(_))\n",
    "        #print(batch_ys[0])\n",
    "        #showImgfrombytes(batch_xs[0])\n",
    "        saver.save(sess, \"./Model/TVLogo_5_relu_softmax.ckpt\",global_step= _ )\n",
    "        print(sess.run(accuracy, feed_dict={X:img_test_float, Y_LABEL: label_test, iftraining: True}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5.Freeze learning model. Use checkpoint file to generate pb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Model\\TVLogo_5_relu_softmax.ckpt-2000\n",
      "INFO:tensorflow:Froze 27 variables.\n",
      "Converted 27 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    #初始化变量\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    #获取最新的checkpoint，其实就是解析了checkpoint文件\n",
    "    latest_ckpt = tf.train.latest_checkpoint(\"./Model\")\n",
    "\n",
    "    #加载图\n",
    "    restore_saver = tf.train.import_meta_graph('./Model/TVLogo_5_relu_softmax.ckpt-1900.meta')\n",
    "\n",
    "    #恢复图，即将weights等参数加入图对应位置中\n",
    "    restore_saver.restore(sess, latest_ckpt)\n",
    "\n",
    "    #将图中的变量转为常量\n",
    "    output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "        sess, sess.graph_def , [\"Y_predict\"])\n",
    "    #将新的图保存到\"/pretrained/graph.pb\"文件中\n",
    "    tf.train.write_graph(output_graph_def, 'pretrained', \"graph.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6. Prediction: Test batch size increase from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bjwshd']\n",
      "['bjwshd', 'cctv5+']\n",
      "['bjwshd', 'cctv5+', 'hnwshd']\n",
      "['bjwshd', 'cctv5+', 'hnwshd', 'hnwshd']\n",
      "['bjwshd', 'cctv5+', 'hnwshd', 'hnwshd', 'cctv1']\n",
      "['bjwshd', 'cctv5+', 'hnwshd', 'hnwshd', 'cctv1', 'cctv5']\n",
      "['bjwshd', 'cctv5+', 'hnwshd', 'hnwshd', 'cctv1', 'cctv5', 'cctv5']\n",
      "['bjwshd', 'cctv5+', 'hnwshd', 'hnwshd', 'cctv1', 'cctv5', 'cctv5', 'hnwshd']\n",
      "['bjwshd', 'cctv5+', 'hnwshd', 'hnwshd', 'cctv1', 'cctv5', 'cctv5', 'hnwshd', 'cctv1hd']\n",
      "['bjwshd', 'cctv5+', 'hnwshd', 'hnwshd', 'cctv1', 'cctv5', 'cctv5', 'hnwshd', 'cctv1hd', 'cctv5+']\n",
      "['bjwshd', 'cctv5+', 'hnwshd', 'hnwshd', 'cctv1', 'cctv5', 'cctv5', 'hnwshd', 'cctv1hd', 'cctv5+', 'bjwshd']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: RuntimeWarning: the frombuffer defaults may change in a future release; for portability, change the call to read:\n",
      "  frombuffer(mode, size, data, 'raw', mode, 0, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def recognize(img_input, pb_file_path):\n",
    "    with tf.Graph().as_default():\n",
    "        output_graph_def = tf.GraphDef()\n",
    "\n",
    "        with open(pb_file_path, \"rb\") as f:\n",
    "            output_graph_def.ParseFromString(f.read())\n",
    "            _ = tf.import_graph_def(output_graph_def, name=\"\")\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            init = tf.global_variables_initializer()\n",
    "            sess.run(init)\n",
    "\n",
    "            input_x = sess.graph.get_tensor_by_name(\"Input:0\")\n",
    "            # print input_x\n",
    "            mode = sess.graph.get_tensor_by_name('Mode:0')\n",
    "            out_softmax = sess.graph.get_tensor_by_name(\"Y_predict:0\")\n",
    "            # print out_softmax\n",
    "            # out_label = sess.graph.get_tensor_by_name(\"output:0\")\n",
    "            # print out_label\n",
    "\n",
    "            # img = io.imread(jpg_path)\n",
    "            # img = transform.resize(img, (224, 224, 3))\n",
    "            \n",
    "            img_try = img_input\n",
    "            #showImgfrombytes(img[7])\n",
    "            #showImgfrombytes(img_try[1])\n",
    "            #showImgfrombytes(img[2])\n",
    "            test_input = np.float32(img_try/255)\n",
    "            #test_input = np.reshape(test_input/255, [1,96*35])\n",
    "            #print(test_input)\n",
    "            img_out_softmax = sess.run(out_softmax, feed_dict={input_x:test_input,mode: False})\n",
    "\n",
    "            #print (\"img_out_softmax:\",img_out_softmax)\n",
    "            prediction_labels = np.argmax(img_out_softmax, axis=1)\n",
    "            #print (\"label:\",prediction_labels)\n",
    "            return prediction_labels\n",
    "            #print('true label:',mnist.test.labels[0])\n",
    "\n",
    "#r = recognize(img_test, \"./ResNet_L152_retrain/pb_model/frozen_model_ResNet_L152.pb\")\n",
    "#print(listmapping(r,TV_LOGO_s))\n",
    "start = 0\n",
    "for i in range(1,12):\n",
    "    r = recognize(img_test[start:start+i], \"./pretrained/graph.pb\")\n",
    "    print(listmapping(r,TV_LOGO_s))\n",
    "showImgfrombytes(img_test[start])\n",
    "showImgfrombytes(img_test[start+1])\n",
    "showImgfrombytes(img_test[start+2])\n",
    "showImgfrombytes(img_test[start+3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7. Test Image one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bjwshd']\n",
      "['cctv5+']\n",
      "['hnwshd']\n",
      "['hnwshd']\n",
      "['cctv1']\n",
      "['cctv5']\n",
      "['cctv5']\n",
      "['hnwshd']\n",
      "['cctv1hd']\n",
      "['cctv5+']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "with tf.Session() as sess:\n",
    "    with open('./pretrained/graph.pb', 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        \n",
    "        for i in range(10):\n",
    "            test_input = np.float32(img_test[i]/255)\n",
    "            test_input = np.reshape(test_input,[1,96*35])\n",
    "            output = tf.import_graph_def(graph_def, input_map={'Input:0':test_input,'Mode:0': False}, return_elements=['Y_predict:0'])\n",
    "            prediction = sess.run(output)\n",
    "            #print(prediction)\n",
    "            r = np.argmax(prediction[0],1)\n",
    "            print(listmapping(r,TV_LOGO_s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
