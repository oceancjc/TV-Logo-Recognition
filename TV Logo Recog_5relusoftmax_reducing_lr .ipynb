{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "import matplotlib.image as mpimg # mpimg 用于读取图片\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "item = 0\n",
    "def next_batch(x,y,batch_size):\n",
    "    global item\n",
    "    while True:\n",
    "        item += batch_size\n",
    "        if item+2*batch_size > x.shape[0]:   item = 0\n",
    "        return x[item:item+batch_size,:],y[item:item+batch_size,:]\n",
    "\n",
    "\n",
    "def load_img(path= \"D:\\\\Unistar\\\\TV Logo Recognition\\\\Logo Data\\\\cctv5+\",num = 10,label = 0,total_label = 3):\n",
    "    a_s = []\n",
    "    for i in range(num):\n",
    "        file = path+ \"/video_out_sd_{}.yuv\".format(i)\n",
    "\n",
    "        f = open(file,'rb')\n",
    "        buf = f.read()\n",
    "        buf = np.frombuffer(buf, dtype=np.uint8)\n",
    "        buf = buf.reshape([1,96*35])\n",
    "        if i == 0:    matrix = buf\n",
    "        else:         matrix = np.concatenate([matrix,buf],axis = 0)\n",
    "        a_s.append(buf)\n",
    "        #lena =  Image.frombuffer('L',(96,35),buf)\n",
    "        #lena.show()\n",
    "        #time.sleep(1)\n",
    "        f.close()\n",
    "\n",
    "    #matrix = np.array(a_s)\n",
    "    \n",
    "    #print(matrix.shape)\n",
    "    label_s = np.zeros( (matrix.shape[0],total_label),dtype = np.float32 )\n",
    "    label_s[:,label] = 1\n",
    "    return matrix,label_s\n",
    "\n",
    "def showImgfrombytes(bytestream,shape = (96,35)):\n",
    "    lena =  Image.frombuffer('L',shape,bytestream)\n",
    "    lena = lena.transpose(Image.FLIP_TOP_BOTTOM) #上下互换\n",
    "    lena.show()\n",
    "    #draw = ImageDraw.Draw(img)\n",
    "    \n",
    "\n",
    "def listmapping(channel_list,LOGO_s):\n",
    "    out_s = []\n",
    "    for i in channel_list:\n",
    "        out_s.append(LOGO_s[int(i)][0])\n",
    "    return out_s\n",
    "    \n",
    "    \n",
    "TV_LOGO_s = [('cctv5+',1022),('cctv1hd',1044),('jswshd',1021),('dfwshd',1001),('cctv5',1001),\n",
    "             ('zjwshd',1001),('cctv1',1001),('bjwshd',1001),('hnwshd',1001),('cctv5hd',1001)]\n",
    "CLASSES = len(TV_LOGO_s)\n",
    "LOGOPATH = \"D:\\\\Unistar\\\\TV Logo Recognition\\\\Logo Data 96x35\\\\\"\n",
    "img_s   = [0]*CLASSES\n",
    "label_s = [0]*CLASSES\n",
    "for i in range(CLASSES):\n",
    "    img_s[i],label_s[i] = load_img(LOGOPATH+TV_LOGO_s[i][0],int(TV_LOGO_s[i][1]),i,CLASSES)\n",
    "\n",
    "\n",
    "img   = img_s[0]\n",
    "label = label_s[0]\n",
    "for i in range(1,len(img_s)):\n",
    "    img   = np.concatenate([img,img_s[i]],axis = 0)\n",
    "    label = np.concatenate([label,label_s[i]],axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8075, 3360) (8075, 10)\n",
      "(2019, 3360) (2019, 10)\n"
     ]
    }
   ],
   "source": [
    "permutation = np.random.permutation(img.shape[0])\n",
    "shuffled_img = img[permutation, :]\n",
    "shuffled_labels = label[permutation, :]\n",
    "\n",
    "total_num = img.shape[0]\n",
    "train_num = int(0.8*total_num)\n",
    "\n",
    "img_train   = shuffled_img[0:train_num,:]\n",
    "label_train = shuffled_labels[0:train_num,:]\n",
    "img_test    = shuffled_img[train_num:,:]\n",
    "label_test  = shuffled_labels[train_num:,:]\n",
    "\n",
    "print(img_train.shape, label_train.shape)\n",
    "print(img_test.shape, label_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(img_train.dtype,label_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "showImgfrombytes(img_test[1550])\n",
    "print(label_test[1550])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8075, 3360)\n",
      "0.130758\n",
      "0.995047\n",
      "0.998019\n",
      "0.999009\n",
      "0.999009\n",
      "0.999009\n",
      "0.999009\n",
      "0.999009\n",
      "0.999009\n",
      "0.999009\n",
      "0.999009\n",
      "0.999009\n",
      "0.999009\n",
      "0.999009\n",
      "0.999009\n",
      "0.999009\n",
      "0.999009\n",
      "0.999009\n",
      "0.999009\n",
      "0.999009\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "#mnist = input_data.read_data_sets(r\"D:\\MachineLearning\\minst\", one_hot=True)\n",
    "\n",
    "def batch_normal(Y,offset_Beta,scale_J,iteration):\n",
    "    exp_moving_avg = tf.train.ExponentialMovingAverage(0.998, iteration) # adding the iteration prevents from averaging across non-existing iterations\n",
    "    mean, variance = tf.nn.moments(Y, [0])\n",
    "    update_moving_averages = exp_moving_avg.apply([mean, variance])\n",
    "    m = exp_moving_avg.average(mean)\n",
    "    v = exp_moving_avg.average(variance)\n",
    "   # Ybn = tf.nn.batch_normalization(Y, m, v, offset_Beta, scale_J, 1e-5)\n",
    "    Ybn = tf.nn.batch_normalization(Y, mean, variance, offset_Beta, scale_J, 1e-5)\n",
    "    return Ybn,update_moving_averages\n",
    "\n",
    "\n",
    "def hidden_layer(X, sizeOutput, iteration = 10, non_linear_name = '',enable_bn=False):\n",
    "    sizeInput = X.shape[1]\n",
    "    W = tf.Variable( tf.truncated_normal([int(sizeInput),int(sizeOutput)],stddev=0.001) )\n",
    "    \n",
    "    if enable_bn:   \n",
    "        Z = tf.matmul(X,W)         #In bach norm, the bias B can be ommited due to the offset\n",
    "        scale_J = tf.Variable(tf.ones([int(sizeOutput)]))\n",
    "        offset_Beta = tf.Variable(tf.zeros([int(sizeOutput)]))\n",
    "        Y, update_moving_averages = batch_normal(Z,offset_Beta,scale_J, iteration)\n",
    "    else:           \n",
    "        B = tf.Variable(tf.zeros([1,sizeOutput]))\n",
    "        Y = tf.matmul(X,W) + B\n",
    "        \n",
    "        \n",
    "    if non_linear_name == '':             return   Y,0\n",
    "    elif non_linear_name == 'softmax':    A = tf.nn.softmax(Y)\n",
    "    elif non_linear_name == 'relu':       A = tf.nn.relu(Y)\n",
    "    elif non_linear_name == 'sigmoid':    A = tf.nn.sigmoid(Y)\n",
    "    return A, update_moving_averages\n",
    "\n",
    "\n",
    "X       = tf.placeholder(tf.float32, [None, 96*35],name = 'Input')\n",
    "Y_LABEL = tf.placeholder(tf.float32, [None, CLASSES], name = 'Label')\n",
    "lr      = tf.placeholder(tf.float32, name = 'LearningRate')\n",
    "iters   = tf.placeholder(tf.int32, name = 'Iterations')\n",
    "\n",
    "A0, update_ema0 = hidden_layer(X,512, iters, 'relu',True)\n",
    "A1, update_ema1 = hidden_layer(A0,256, iters, 'relu',True)\n",
    "A2, update_ema2 = hidden_layer(A1,128,iters, 'relu',True)\n",
    "A3, update_ema3 = hidden_layer(A2,64, iters, 'relu',True)\n",
    "A4, update_ema4 = hidden_layer(A3,32, iters, 'relu',True)\n",
    "Y_linear,nocare = hidden_layer(A4, Y_LABEL.shape[1]) \n",
    "Y_predict       = tf.nn.softmax(Y_linear,name = 'Y_predict')\n",
    "update_ema = tf.group(update_ema0, update_ema1, update_ema2, update_ema3, update_ema4)\n",
    "#update_ema = tf.group(update_ema0, update_ema2, update_ema3)\n",
    "\n",
    "#cross_entropy = tf.reduce_mean(\n",
    "#    tf.nn.softmax_cross_entropy_with_logits(labels=Y_LABEL, logits=Y_linear))\n",
    "cross_entropy = tf.reduce_mean( -tf.reduce_sum(Y_LABEL * tf.log(Y_predict), reduction_indices=[1]) )\n",
    "#train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(cross_entropy)\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "\n",
    "max_learning_rate = 0.1\n",
    "min_learning_rate = 0.001\n",
    "decay_speed = 2000.0\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "img_train_float = np.float32(img_train/255)\n",
    "img_test_float = np.float32(img_test/255)\n",
    "print(img_train_float.shape)\n",
    "for _ in range(2000):\n",
    "    batch_xs, batch_ys= next_batch(img_train_float,label_train,500)\n",
    "    learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * np.exp(-_/decay_speed)\n",
    "    sess.run(train_step, feed_dict={X: batch_xs, Y_LABEL: batch_ys, lr:learning_rate})\n",
    "    if _%100 == 0:\n",
    "        correct_prediction = tf.equal(tf.argmax(Y_linear, 1), tf.argmax(Y_LABEL, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        #print('This is round {} ...'.format(_))\n",
    "        #print(batch_ys[0])\n",
    "        #showImgfrombytes(batch_xs[0])\n",
    "        saver.save(sess, \"./Model/TVLogo_5_relu_softmax.ckpt\",global_step= _ )\n",
    "        print(sess.run(accuracy, feed_dict={X:img_test_float, Y_LABEL: label_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver() \n",
    "saver.save(sess, \"./Model/TVLogo_5_relu_softmax.ckpt\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"./Model/TVLogo_5_relu_softmax.ckpt\")\n",
    "print(sess.run(tf.get_default_graph().get_tensor_by_name(\"train_step\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Model\\TVLogo_5_relu_softmax.ckpt-1900\n",
      "INFO:tensorflow:Froze 17 variables.\n",
      "Converted 17 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    #初始化变量\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    #获取最新的checkpoint，其实就是解析了checkpoint文件\n",
    "    latest_ckpt = tf.train.latest_checkpoint(\"./Model\")\n",
    "\n",
    "    #加载图\n",
    "    restore_saver = tf.train.import_meta_graph('./Model/TVLogo_5_relu_softmax.ckpt-1900.meta')\n",
    "\n",
    "    #恢复图，即将weights等参数加入图对应位置中\n",
    "    restore_saver.restore(sess, latest_ckpt)\n",
    "\n",
    "    #将图中的变量转为常量\n",
    "    output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "        sess, sess.graph_def , [\"Y_predict\"])\n",
    "    #将新的图保存到\"/pretrained/graph.pb\"文件中\n",
    "    tf.train.write_graph(output_graph_def, 'pretrained', \"graph.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-00bc11ea1b82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconstant_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_variables_to_constants\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Y_predict'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFastGFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./pretrained/graph.pb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstant_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py\u001b[0m in \u001b[0;36mconvert_variables_to_constants\u001b[1;34m(sess, input_graph_def, output_node_names, variable_names_whitelist, variable_names_blacklist)\u001b[0m\n\u001b[0;32m    222\u001b[0m       \u001b[0mvariable_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\":0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mvariable_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[0mreturned_variables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[0mreturned_variables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;31m# Check session.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Attempted to use a closed Session.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1048\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "constant_graph = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def,['Y_predict'])\n",
    "with tf.gfile.FastGFile('./pretrained/graph.pb', mode='wb') as f:\n",
    "    f.write(constant_graph.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "with tf.Session() as sess:\n",
    "    with open('./pretrained/graph.pb', 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        \n",
    "        img_tmp = img_test[0:25]\n",
    "        test_input = np.float32(img_tmp)\n",
    "        #test_input = np.reshape(test_input, [1,96*35])\n",
    "        #print(test_input)\n",
    "        #test_input = np.zeros([1,96*35],dtype = np.float32)\n",
    "        #for i in range(5):    showImgfrombytes(img_tmp[i])\n",
    "        print(test_input.shape)\n",
    "        output = tf.import_graph_def(graph_def, input_map={'Input:0':test_input}, return_elements=['Y_predict:0'])\n",
    "        prediction = sess.run(output)\n",
    "        #print(prediction)\n",
    "        print(np.argmax(prediction[0],1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cctv5+']\n",
      "['cctv5hd', 'hnwshd']\n",
      "['cctv1', 'jswshd', 'cctv1hd']\n",
      "['cctv1', 'jswshd', 'cctv1hd', 'cctv5']\n",
      "['cctv1', 'jswshd', 'cctv1hd', 'cctv5', 'zjwshd']\n",
      "['cctv1', 'jswshd', 'cctv1hd', 'cctv5', 'zjwshd', 'dfwshd']\n",
      "['cctv1', 'cctv5+', 'cctv5hd', 'cctv5', 'zjwshd', 'zjwshd', 'jswshd']\n",
      "['cctv1', 'jswshd', 'cctv5hd', 'cctv5', 'zjwshd', 'zjwshd', 'jswshd', 'cctv5+']\n",
      "['cctv1', 'jswshd', 'cctv5hd', 'cctv5', 'zjwshd', 'zjwshd', 'jswshd', 'cctv5+', 'hnwshd']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: RuntimeWarning: the frombuffer defaults may change in a future release; for portability, change the call to read:\n",
      "  frombuffer(mode, size, data, 'raw', mode, 0, 1)\n"
     ]
    }
   ],
   "source": [
    "def recognize(img_input, pb_file_path):\n",
    "    with tf.Graph().as_default():\n",
    "        output_graph_def = tf.GraphDef()\n",
    "\n",
    "        with open(pb_file_path, \"rb\") as f:\n",
    "            output_graph_def.ParseFromString(f.read())\n",
    "            _ = tf.import_graph_def(output_graph_def, name=\"\")\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            init = tf.global_variables_initializer()\n",
    "            sess.run(init)\n",
    "\n",
    "            input_x = sess.graph.get_tensor_by_name(\"Input:0\")\n",
    "            # print input_x\n",
    "            out_softmax = sess.graph.get_tensor_by_name(\"Y_predict:0\")\n",
    "            # print out_softmax\n",
    "            # out_label = sess.graph.get_tensor_by_name(\"output:0\")\n",
    "            # print out_label\n",
    "\n",
    "            # img = io.imread(jpg_path)\n",
    "            # img = transform.resize(img, (224, 224, 3))\n",
    "            \n",
    "            img_try = img_input\n",
    "            #showImgfrombytes(img[7])\n",
    "            #showImgfrombytes(img_try[1])\n",
    "            #showImgfrombytes(img[2])\n",
    "            test_input = np.float32(img_try/255)\n",
    "            #test_input = np.reshape(test_input/255, [1,96*35])\n",
    "            #print(test_input)\n",
    "            img_out_softmax = sess.run(out_softmax, feed_dict={input_x:test_input})\n",
    "\n",
    "            #print (\"img_out_softmax:\",img_out_softmax)\n",
    "            prediction_labels = np.argmax(img_out_softmax, axis=1)\n",
    "            #print (\"label:\",prediction_labels)\n",
    "            return prediction_labels\n",
    "            #print('true label:',mnist.test.labels[0])\n",
    "\n",
    "#r = recognize(img_test, \"./ResNet_L152_retrain/pb_model/frozen_model_ResNet_L152.pb\")\n",
    "#print(listmapping(r,TV_LOGO_s))\n",
    "start = 10\n",
    "for i in range(1,10):\n",
    "    r = recognize(img_test[start:start+i], \"./pretrained/graph.pb\")\n",
    "    print(listmapping(r,TV_LOGO_s))\n",
    "showImgfrombytes(img_test[start])\n",
    "showImgfrombytes(img_test[start+1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    " \n",
    "#os.environ['CUDA_VISIBLE_DEVICES']='2'  #设置GPU\n",
    "model_path  = \"./Model/TVLogo_5_relu_softmax.ckpt-1900\" #设置model的路径\n",
    " \n",
    "def main():\n",
    "    tf.reset_default_graph()\n",
    "    saver = tf.train.import_meta_graph(\"./Model/TVLogo_5_relu_softmax.ckpt-1900.meta\")\n",
    "    #flow = tf.cast(flow, tf.uint8, 'out') #设置输出类型以及输出的接口名字，为了之后的调用pb的时候使用\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, model_path)\n",
    "        #保存图\n",
    "        tf.train.write_graph(sess.graph_def, './ResNet_L152_retrain/pb_model', 'model_ResNet_L153.pb')\n",
    "        #把图和参数结构一起\n",
    "        freeze_graph.freeze_graph('ResNet_L152_retrain/pb_model/model_ResNet_L153.pb',\n",
    "                                  '',\n",
    "                                  False,\n",
    "                                  model_path,\n",
    "                                  'Y_predict',\n",
    "                                  'save/restore_all',\n",
    "                                  'save/Const:0',\n",
    "                                  'ResNet_L152_retrain/pb_model/frozen_model_ResNet_L153.pb',\n",
    "                                  False,\n",
    "                                  \"\")\n",
    "    print(\"done\")\n",
    "     \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02352941  0.02352941  0.02352941 ...,  0.02352941  0.01960784\n",
      "   0.01960784]]\n",
      "['cctv5+']\n",
      "[[ 0.07450981  0.07450981  0.07450981 ...,  0.17647059  0.18039216\n",
      "   0.18039216]]\n",
      "['cctv5+']\n",
      "[[ 0.25882354  0.28235295  0.29803923 ...,  0.37254903  0.34117648\n",
      "   0.27843139]]\n",
      "['cctv5+']\n",
      "[[ 0.13725491  0.25098041  0.52549022 ...,  0.10588235  0.10980392\n",
      "   0.10980392]]\n",
      "['cctv5+']\n",
      "[[ 0.8392157   0.84313726  0.84313726 ...,  0.78039217  0.78039217\n",
      "   0.78039217]]\n",
      "['cctv5+']\n",
      "[[ 0.28627452  0.28627452  0.28627452 ...,  0.39607844  0.38431373\n",
      "   0.38039216]]\n",
      "['cctv5+']\n",
      "[[ 0.36470589  0.36470589  0.36470589 ...,  0.36470589  0.36078432\n",
      "   0.36078432]]\n",
      "['cctv5+']\n",
      "[[ 0.50196081  0.49803922  0.50588238 ...,  0.76078433  0.7647059\n",
      "   0.7647059 ]]\n",
      "['cctv5+']\n",
      "[[ 0.36078432  0.36470589  0.36862746 ...,  0.25490198  0.25490198\n",
      "   0.25490198]]\n",
      "['cctv5+']\n",
      "[[ 0.50196081  0.50196081  0.50980395 ...,  0.75294119  0.75686276\n",
      "   0.7647059 ]]\n",
      "['cctv5+']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "with tf.Session() as sess:\n",
    "    with open('./pretrained/graph.pb', 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        \n",
    "        for i in range(10):\n",
    "            test_input = np.float32(img_train[i]/255)\n",
    "            test_input = np.reshape(test_input,[1,96*35])\n",
    "        #test_input = np.float32(img/255)\n",
    "        #test_input = np.reshape(test_input, [1,96*35])\n",
    "            print(test_input)\n",
    "        #test_input = np.zeros([1,96*35],dtype = np.float32)\n",
    "        #showImgfrombytes(img)\n",
    "            #print(test_input.shape)\n",
    "            output = tf.import_graph_def(graph_def, input_map={'Input:0':test_input}, return_elements=['Y_predict:0'])\n",
    "            prediction = sess.run(output)\n",
    "            #print(prediction)\n",
    "            r = np.argmax(prediction[0],1)\n",
    "            print(listmapping(r,TV_LOGO_s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
